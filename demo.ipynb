{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMHArnj2eZWRGGmqrDSgjTk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LeslieZhoa/Simple-Lora/blob/main/demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 环境测试\n",
        "%cd /content/\n",
        "! nvidia-smi"
      ],
      "metadata": {
        "id": "nWU6TpWTHfm4",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1JmBRIMQwRvO",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title 环境准备\n",
        "!rm -rf Simple-Lora\n",
        "!git clone https://github.com/LeslieZhoa/Simple-Lora.git\n",
        "%cd Simple-Lora/\n",
        "!pip install -r requirements.txt\n",
        "!pip uninstall torchtext -y\n",
        "!git lfs install\n",
        "!wget https://storage.googleapis.com/sfr-vision-language-research/BLIP/models/model_base_caption_capfilt_large.pth -P ./pretrained_models\n",
        "%cd pretrained_models\n",
        "!git clone https://huggingface.co/bert-base-uncased\n",
        "!git clone https://huggingface.co/naonovn/chilloutmix_NiPrunedFp32Fix\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 基础模型safetensor转换\n",
        "!python process/convert_original_stable_diffusion_to_difdusers.py \\\n",
        "    --checkpoint_path ./pretrained_models/chilloutmix_NiPrunedFp32Fix/chilloutmix_NiPrunedFp32Fix.safetensors \\\n",
        "    --dump_path ./pretrained_models/chilloutmixNiPruned_Tw1O --from_safetensors"
      ],
      "metadata": {
        "id": "wAh4HAL7xIdj",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 选择训练lora的数据\n",
        "from google.colab import files\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import shutil\n",
        "import os.path as osp\n",
        "import os\n",
        "\n",
        "\n",
        "uploaded_imgs_path = 'dataset/custom'\n",
        "if not osp.exists(uploaded_imgs_path) : os.makedirs(uploaded_imgs_path)\n",
        "\n",
        "def upload_img():\n",
        "  uploaded_img = files.upload()\n",
        "  uploadded_img_name = list(uploaded_img.keys())[0]\n",
        "\n",
        "  !mv \"{uploadded_img_name}\" \"{uploaded_imgs_path}\"\n",
        "\n",
        "  print(f\"move file {uploadded_img_name} to {uploaded_imgs_path} \")\n",
        "  return os.path.join(uploaded_imgs_path,uploadded_img_name)\n",
        "up_mode = '\\u4E0A\\u4F20' #@param ['默认', '上传']\n",
        "if up_mode == '默认':\n",
        "  img_path = 'dataset/custom/11.jpeg'\n",
        "else:\n",
        "  !rm dataset/custom/*\n",
        "  img_path = upload_img()\n",
        "img = cv2.imread(img_path)\n",
        "cv2_imshow(img)"
      ],
      "metadata": {
        "id": "eHqg0R7h2E4R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 获取图片文本信息"
      ],
      "metadata": {
        "id": "8hU7wS2OJWER"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python process/run_caption.py --img_base ./dataset/custom"
      ],
      "metadata": {
        "id": "aJZqzjs83g2O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "查看dataset/custom中的txt文本,并设置替换文本"
      ],
      "metadata": {
        "id": "wJu8fSJvL6M8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ####**替换文本设置:**\n",
        "ori_text = \"an asian woman\" #@param {type: 'string'}\n",
        "new_text = \"<lyf>\" #@param {type: 'string'}\n",
        "with open('1.txt','w') as f:\n",
        "  f.write(ori_text)\n",
        "with open('2.txt','w') as f:\n",
        "  f.write(new_text)\n",
        "!python process/change_txt.py --img_base ./dataset/custom --ori_txt \"$(head -n 1 1.txt)\" --new_txt \"$(head -n 1 2.txt)\""
      ],
      "metadata": {
        "id": "kJ06vWp_Lert"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ####**设置训练分辨率**\n",
        "#@markdown 由于colab显存限制，如果使用512分辨率会内存溢出，所以这里使用384分辨率，但是效果会差很多\n",
        "resolution = 384 #@param {type: 'integer'}\n",
        "os.environ['resolution'] = str(resolution)\n",
        "!python  train.py  --batch_size 1 --dist --print_interval 1 --train_text_encoder --save_interval 300 --eval 0 --resolution $resolution"
      ],
      "metadata": {
        "id": "VhW0amf74Ztg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "展示训练的lora效果了"
      ],
      "metadata": {
        "id": "_LGnqZvON2Bd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ####**输入文本设置:**\n",
        "prompt = \"<dlrb>,solo, long hair, black hair, choker, breasts, earrings, blue eyes, jewelry, lipstick, makeup, dark, bare shoulders, mountain, night, upper body, dress, large breasts, ((masterpiece))\" #@param {type: 'string'}\n",
        "with open('1.txt','w') as f:\n",
        "  f.write(prompt)\n",
        "!python inference.py \\\n",
        "    --mode 'lora' \\\n",
        "    --lora_path checkpoint/Lora/000-00000600.pth \\\n",
        "    --prompt  \"$(head -n 1 1.txt)\" \\\n",
        "    --outpath results/1.png \\\n",
        "    --num_images_per_prompt 1 \\\n",
        "    --width 384 --height 384\n",
        "img = cv2.imread('results/1.png')\n",
        "cv2_imshow(img)"
      ],
      "metadata": {
        "id": "bDaFCRU6_NSv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 删除一些模型，存储不够拉！！！\n",
        "!rm -rf pretrained_models/bert-base-uncased \\\n",
        "     checkpoint/Lora/000-00000000.pth checkpoint/Lora/000-00000300.pth"
      ],
      "metadata": {
        "id": "PIcVI5exCkp4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 准备inpaiting模型\n",
        "%cd pretrained_models\n",
        "!git clone https://huggingface.co/runwayml/stable-diffusion-inpainting\n",
        "%cd ..\n",
        "!wget https://github.com/LeslieZhoa/LVT/releases/download/v0.0/face_parsing.pt -P pretrained_models"
      ],
      "metadata": {
        "id": "52oqmBZRDi_m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "展示inpaiting效果，如果结合controlnet(由于显存限制，暂不演示)就可以生成自己的虚拟偶像了"
      ],
      "metadata": {
        "id": "_AWtedNCO6wj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ####**输入文本设置:**\n",
        "prompt = \"green hair,short hair,curly hair, green hair,beach,seaside\" #@param {type: 'string'}\n",
        "with open('1.txt','w') as f:\n",
        "  f.write(prompt)\n",
        "!python inference.py \\\n",
        "    --mode 'inpait' \\\n",
        "    --inpait_path pretrained_models/stable-diffusion-inpainting \\\n",
        "    --mask_area all \\\n",
        "    --ref_img results/1.png \\\n",
        "    --prompt  \"$(head -n 1 1.txt)\" \\\n",
        "    --outpath results/2.png \\\n",
        "    --num_images_per_prompt 1\n",
        "img = cv2.imread('results/2.png')\n",
        "cv2_imshow(img)"
      ],
      "metadata": {
        "id": "FwniF5W4FaD7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}